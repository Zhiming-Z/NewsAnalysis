# 热点新闻爬取与展示系统 - 技术方案文档

## 1. 项目概述

### 1.1 项目背景

开发一个热点新闻爬取与展示系统，能够自动获取最新的热点新闻，并按照不同类别在前端页面进行展示。

### 1.2 核心功能

- 多源新闻数据爬取
- 新闻自动分类（经济、政治、艺术、科技、体育等）
- 前端响应式展示
- 搜索和筛选功能

---

## 2. 技术选型

### 2.1 后端技术栈

| 组件 | 技术选择 | 选择理由 |
|------|----------|----------|
| **编程语言** | Python 3.11+ | 丰富的爬虫生态、成熟的数据处理能力 |
| **Web框架** | FastAPI | 高性能、自动生成 API 文档、异步支持 |
| **爬虫框架** | Scrapy + Selenium | Scrapy 高效批量爬取，Selenium 处理动态页面 |
| **任务调度** | Celery + Redis | 分布式任务队列，支持定时任务 |
| **缓存** | Redis | 高性能缓存，支持数据去重 |

### 2.2 数据库方案

| 组件 | 技术选择 | 选择理由 |
|------|----------|----------|
| **主数据库** | PostgreSQL 15+ | 稳定可靠、支持全文搜索、JSON 字段支持 |
| **搜索引擎** | Elasticsearch (可选) | 大规模新闻搜索优化 |

### 2.3 前端技术栈

| 组件 | 技术选择 | 选择理由 |
|------|----------|----------|
| **框架** | Vue.js 3 + TypeScript | 轻量、易学、组件化开发 |
| **UI库** | Element Plus | 丰富的组件库、良好的中文支持 |
| **状态管理** | Pinia | Vue 3 官方推荐、简洁易用 |
| **HTTP客户端** | Axios | 功能完善、拦截器支持 |
| **构建工具** | Vite | 快速的开发构建体验 |

### 2.4 部署方案

| 组件 | 技术选择 | 选择理由 |
|------|----------|----------|
| **容器化** | Docker + Docker Compose | 环境一致性、便于部署 |
| **Web服务器** | Nginx | 反向代理、静态资源服务 |
| **进程管理** | Supervisor / PM2 | 后端服务进程管理 |

---

## 3. 系统架构

### 3.1 整体架构图

```
┌─────────────────────────────────────────────────────────────────────────┐
│                              用户层                                      │
│                         ┌─────────────┐                                  │
│                         │   浏览器     │                                  │
│                         └──────┬──────┘                                  │
└────────────────────────────────┼────────────────────────────────────────┘
                                 │
┌────────────────────────────────┼────────────────────────────────────────┐
│                              接入层                                      │
│                         ┌──────┴──────┐                                  │
│                         │    Nginx    │                                  │
│                         └──────┬──────┘                                  │
└────────────────────────────────┼────────────────────────────────────────┘
                                 │
         ┌───────────────────────┴───────────────────────┐
         │                                               │
         ▼                                               ▼
┌─────────────────────────┐                 ┌─────────────────────────┐
│       前端服务层         │                 │       后端服务层         │
│  ┌───────────────────┐  │                 │  ┌───────────────────┐  │
│  │   Vue.js 前端     │  │                 │  │  FastAPI 后端     │  │
│  │   (静态资源)      │  │                 │  │  (RESTful API)    │  │
│  └───────────────────┘  │                 │  └─────────┬─────────┘  │
└─────────────────────────┘                 │            │            │
                                            │  ┌─────────┴─────────┐  │
                                            │  │   业务逻辑层       │  │
                                            │  │  - 新闻服务       │  │
                                            │  │  - 分类服务       │  │
                                            │  │  - 搜索服务       │  │
                                            │  └───────────────────┘  │
                                            └─────────────────────────┘
                                                         │
┌────────────────────────────────────────────────────────┼────────────────┐
│                              数据层                     │                │
│         ┌──────────────────────────────────────────────┘                │
│         │                                                               │
│         ▼                                                               │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐                  │
│  │ PostgreSQL  │    │    Redis    │    │ Elasticsearch│                 │
│  │  (主数据库)  │    │   (缓存)    │    │  (搜索-可选) │                 │
│  └─────────────┘    └─────────────┘    └─────────────┘                  │
└─────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────┐
│                              爬虫层                                      │
│  ┌───────────────────────────────────────────────────────────────────┐  │
│  │                        Celery Worker                               │  │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐                 │  │
│  │  │ Scrapy 爬虫  │  │ Selenium    │  │  数据清洗    │                │  │
│  │  │ (静态页面)   │  │ (动态页面)   │  │  (去重/分类) │                │  │
│  │  └─────────────┘  └─────────────┘  └─────────────┘                 │  │
│  └───────────────────────────────────────────────────────────────────┘  │
│                                │                                        │
│                         ┌──────┴──────┐                                 │
│                         │ Celery Beat │ (定时调度)                      │
│                         └─────────────┘                                 │
└─────────────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────────────┐
│                           外部新闻源                                     │
│  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌─────────┐       │
│  │ 新浪新闻 │  │ 网易新闻 │  │ 腾讯新闻 │  │ 今日头条 │  │ 其他源   │      │
│  └─────────┘  └─────────┘  └─────────┘  └─────────┘  └─────────┘       │
└─────────────────────────────────────────────────────────────────────────┘
```

### 3.2 数据流程图

```
┌─────────────────────────────────────────────────────────────────────────┐
│                           数据流程                                       │
└─────────────────────────────────────────────────────────────────────────┘

  ┌──────────┐     ┌──────────┐     ┌──────────┐     ┌──────────┐
  │ 定时触发  │ ──► │ 爬虫采集  │ ──► │ 数据清洗  │ ──► │ 数据去重  │
  └──────────┘     └──────────┘     └──────────┘     └──────────┘
                                                           │
                                                           ▼
  ┌──────────┐     ┌──────────┐     ┌──────────┐     ┌──────────┐
  │ 前端展示  │ ◄── │ API 查询  │ ◄── │ 数据存储  │ ◄── │ 自动分类  │
  └──────────┘     └──────────┘     └──────────┘     └──────────┘

详细流程说明：
1. 定时触发：Celery Beat 按配置的时间间隔触发爬虫任务
2. 爬虫采集：Scrapy/Selenium 从各新闻源获取原始数据
3. 数据清洗：提取标题、内容、时间、来源等字段
4. 数据去重：通过 URL 和标题 Hash 进行去重
5. 自动分类：基于关键词和规则进行新闻分类
6. 数据存储：写入 PostgreSQL 数据库
7. API 查询：FastAPI 提供 RESTful 接口
8. 前端展示：Vue.js 前端渲染展示
```

### 3.3 模块划分

```
hot-news-system/
├── backend/                    # 后端服务
│   ├── app/
│   │   ├── api/               # API 路由
│   │   │   ├── v1/
│   │   │   │   ├── news.py    # 新闻接口
│   │   │   │   ├── category.py # 分类接口
│   │   │   │   └── search.py  # 搜索接口
│   │   │   └── deps.py        # 依赖注入
│   │   ├── core/              # 核心配置
│   │   │   ├── config.py      # 配置管理
│   │   │   └── security.py    # 安全配置
│   │   ├── models/            # 数据模型
│   │   │   ├── news.py        # 新闻模型
│   │   │   └── category.py    # 分类模型
│   │   ├── schemas/           # Pydantic 模式
│   │   │   ├── news.py
│   │   │   └── category.py
│   │   ├── services/          # 业务逻辑
│   │   │   ├── news_service.py
│   │   │   └── category_service.py
│   │   └── main.py            # 应用入口
│   ├── requirements.txt
│   └── Dockerfile
│
├── crawler/                    # 爬虫服务
│   ├── spiders/               # 爬虫定义
│   │   ├── sina_spider.py
│   │   ├── netease_spider.py
│   │   └── tencent_spider.py
│   ├── pipelines/             # 数据管道
│   │   ├── clean_pipeline.py
│   │   ├── dedup_pipeline.py
│   │   └── classify_pipeline.py
│   ├── tasks/                 # Celery 任务
│   │   └── crawl_tasks.py
│   ├── scrapy.cfg
│   └── Dockerfile
│
├── frontend/                   # 前端服务
│   ├── src/
│   │   ├── api/               # API 调用
│   │   ├── components/        # Vue 组件
│   │   ├── views/             # 页面视图
│   │   ├── stores/            # Pinia 状态
│   │   ├── router/            # 路由配置
│   │   └── App.vue
│   ├── package.json
│   └── Dockerfile
│
├── docker-compose.yml          # Docker 编排
├── nginx.conf                  # Nginx 配置
└── README.md                   # 项目说明
```

---

## 4. 新闻源调研

### 4.1 推荐新闻源

| 新闻源 | 类型 | 数据获取方式 | 优先级 |
|--------|------|--------------|--------|
| **新浪新闻** | 综合 | RSS/API | 高 |
| **网易新闻** | 综合 | HTML 解析 | 高 |
| **腾讯新闻** | 综合 | HTML 解析/API | 高 |
| **今日头条** | 综合 | API (需模拟) | 中 |
| **澎湃新闻** | 时政 | HTML 解析 | 中 |
| **36氪** | 科技 | RSS/API | 中 |
| **虎扑体育** | 体育 | HTML 解析 | 中 |
| **财新网** | 财经 | HTML 解析 | 中 |

### 4.2 数据结构分析

各新闻源的通用数据字段：

```json
{
  "title": "新闻标题",
  "content": "新闻正文内容",
  "summary": "新闻摘要",
  "source": "来源网站",
  "source_url": "原文链接",
  "author": "作者",
  "publish_time": "发布时间",
  "images": ["图片URL列表"],
  "tags": ["标签列表"],
  "category": "分类"
}
```

### 4.3 新闻分类规则

基于关键词的分类规则：

| 分类 | 关键词示例 |
|------|-----------|
| **经济** | 股市、财经、金融、GDP、贸易、投资、银行、基金 |
| **政治** | 政府、政策、外交、会议、领导人、选举、法律 |
| **科技** | AI、人工智能、互联网、芯片、5G、新能源、科技 |
| **体育** | 足球、篮球、奥运、世界杯、比赛、运动员、赛事 |
| **艺术** | 电影、音乐、艺术、文化、展览、演出、明星 |
| **其他** | 不匹配以上分类的新闻 |

---

## 5. 非功能性需求

### 5.1 性能要求

| 指标 | 要求 |
|------|------|
| API 响应时间 | < 200ms (P95) |
| 爬虫采集频率 | 每30分钟一次 |
| 单次爬取数量 | 100-500 条 |
| 并发用户数 | 支持 1000+ |

### 5.2 安全要求

- 爬虫遵守 robots.txt 协议
- 设置合理的爬取频率，避免对源站造成压力
- API 接口添加速率限制
- 敏感配置使用环境变量

### 5.3 可扩展性

- 支持动态添加新的新闻源
- 支持自定义分类规则
- 数据库支持水平扩展
- 爬虫服务支持分布式部署

---

## 6. 风险评估

| 风险 | 影响 | 应对措施 |
|------|------|----------|
| 新闻源结构变化 | 爬取失败 | 模块化爬虫设计，便于快速修复 |
| 被源站封禁 | 无法获取数据 | 使用代理池、控制爬取频率 |
| 数据量增长过快 | 存储压力 | 定期清理过期数据、分库分表 |
| 分类准确率低 | 用户体验差 | 引入机器学习分类、人工审核 |

---

## 7. 里程碑计划

| 阶段 | 主要任务 | 交付物 |
|------|----------|--------|
| **阶段1** | 技术方案设计 | 本文档 |
| **阶段2** | 爬虫开发 | 核心爬虫模块 |
| **阶段3** | 后端 API | RESTful API 服务 |
| **阶段4** | 前端开发 | Vue.js 前端应用 |
| **阶段5** | 测试优化 | 测试报告 |
| **阶段6** | 部署上线 | 生产环境 |

---

## 附录

### A. 参考资料

- [FastAPI 官方文档](https://fastapi.tiangolo.com/)
- [Scrapy 官方文档](https://docs.scrapy.org/)
- [Vue.js 官方文档](https://vuejs.org/)
- [PostgreSQL 文档](https://www.postgresql.org/docs/)

### B. 文档版本

| 版本 | 日期 | 修改说明 | 作者 |
|------|------|----------|------|
| v1.0 | 2026-01-30 | 初始版本 | - |
